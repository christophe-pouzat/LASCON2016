<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2016-02-04 jeu. 17:29 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>Origin Of The (High Frequency) Extra-cellular Signal</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="Christophe Pouzat" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  pre.src-sh:before    { content: 'sh'; }
  pre.src-bash:before  { content: 'sh'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-R:before     { content: 'R'; }
  pre.src-perl:before  { content: 'Perl'; }
  pre.src-java:before  { content: 'Java'; }
  pre.src-sql:before   { content: 'SQL'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2013 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Origin Of The (High Frequency) Extra-cellular Signal</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline1">1. Introduction</a></li>
<li><a href="#orgheadline4">2. Relation between membrane potential and extracellular potential</a>
<ul>
<li><a href="#orgheadline2">2.1. Basic equations</a></li>
<li><a href="#orgheadline3">2.2. Membrane current density</a></li>
</ul>
</li>
<li><a href="#orgheadline13">3. Numerical integration of the H &amp; H equation</a>
<ul>
<li><a href="#orgheadline8">3.1. A standardized form for the non-linear reaction-diffusion equations</a>
<ul>
<li><a href="#orgheadline5">3.1.1. The heat equation</a></li>
<li><a href="#orgheadline6">3.1.2. Adding the reaction term: Lee's method</a></li>
<li><a href="#orgheadline7">3.1.3. Boundary conditions</a></li>
</ul>
</li>
<li><a href="#orgheadline9">3.2. Python code doing the job</a></li>
<li><a href="#orgheadline10">3.3. Some functions definitions</a></li>
<li><a href="#orgheadline11">3.4. Checking against Cooley and Dodge (1966) results</a></li>
<li><a href="#orgheadline12">3.5. Checking against the traveling wave solution</a></li>
</ul>
</li>
<li><a href="#orgheadline15">4. Numerical investigation of the radius effect on the extracellular potential</a>
<ul>
<li><a href="#orgheadline14">4.1. A fast way to do the job</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgheadline1" class="outline-2">
<h2 id="orgheadline1"><span class="section-number-2">1</span> Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
We want to explore here the basic properties of the <i>extra-cellular</i> potential generated by a uniform active&#x2014;that is, able to propagate an action potential (or <i>spike</i>)&#x2014;cable or axon. We are going to use the conductance model of <a href="http://onlinelibrary.wiley.com/doi/10.1113/jphysiol.1952.sp004764/abstract">Hodgkin and Huxley (1952)</a> together with the cable model making the "full" H &amp; H model.
</p>

<p>
Remember that H &amp; H <i>did not</i> solve their full model in their <i>opus magnum</i>, remember also that the <i>mechanical calculator</i> they had at this time was far less powerful that any of the smartphones everyone has nowadays in his/her pocket. They used a "trick" looking at the propagation of a waveform without deformation at a constant speed \(\theta\), that is, a spike or action potential. In this way the spatial derivatives of the membrane potential can be expressed as time derivatives (as we will see bellow) and the partial differential equation (PDE) of the full model can be replaced by ordinary differential equations (ODE).
</p>

<p>
So we are going to start by deriving the expression of the extra-cellular potential generated by a "cable like neurite"&#x2014;a neurite with a large length to radius ratio&#x2014;that can approximated by a <i>line source</i>. We will follow a classical development that is very clearly explained in the book of Plonsey and Barr (2007) <i>Bioelectricity. A Quantitative Approach</i>, published by Springer. This development will lead us to an equation relating the extra-cellular potential to the integral of the weighted second partial derivative of the membrane potential with respect to space, \(\partial^2 V_m(x,t) / \partial x^2\). The H &amp; H model will give us actual values for this derivative but that will require a numerical solution. We will then explore the effect of the axonal diameter on the extra-cellular potential. 
</p>
</div>
</div>

<div id="outline-container-orgheadline4" class="outline-2">
<h2 id="orgheadline4"><span class="section-number-2">2</span> Relation between membrane potential and extracellular potential</h2>
<div class="outline-text-2" id="text-2">
</div><div id="outline-container-orgheadline2" class="outline-3">
<h3 id="orgheadline2"><span class="section-number-3">2.1</span> Basic equations</h3>
<div class="outline-text-3" id="text-2-1">
<p>
The electrostatic potential \(\Phi_e\) [mV] generated by a constant <b>point source</b> of intensity \(I_0\) [mA] is given by: 
</p>
\begin{align}\label{eq:stat}\tag{1} \Phi_e = \frac{1}{4 \pi \sigma_e} \frac{I_0}{r} \, ,\end{align} 
<p>
where \(\sigma_e\) [S/cm] is the conductivity of the extracellular medium assumed homogeneous and \(r\) [cm] is the distance between the source and the electrode (Plonsey and Barr, 2007, <i>Bioelectricity: A Quantitative Approach</i>, p. 29).
</p>

<p>
For an extended source with a large length to diameter ratio (a cable) that can be approximated by a <b>line source</b>; the generalization of the previous equation for a continuous line source along the x axis (between \(x_{min}\) and \(x_{max}\)) of the 3D Euclidean space equipped with Cartesian coordinates when the electrode is located at \((X,Y,Z)\) is: 
</p>
\begin{align}\label{eq:stat1}\tag{2} \Phi_e(X,Y,Z) = \frac{1}{4 \pi \sigma_e} \int_{x_{min}}^{x_{max}} \frac{i_m(x)}{r(x)} dx \, ,\end{align} 
<p>
where: 
</p>
\begin{align}\tag{3} r(x) \doteq \sqrt{(x-X)^2+Y^2+Z^2}\;,\end{align} 
<p>
and \(i_m(x)\) [mA/cm] is the <i>current density</i> at position \(x\) [cm] along the cable.
</p>
</div>
</div>

<div id="outline-container-orgheadline3" class="outline-3">
<h3 id="orgheadline3"><span class="section-number-3">2.2</span> Membrane current density</h3>
<div class="outline-text-3" id="text-2-2">
<p>
We get an expression for \(i_m(x)\) by considering a small piece of cable of radius \(a\) [cm] and of length \(\Delta x\) [cm] (Plonsey and Barr, 2007).
</p>

<p>
If the intracellular potential at position \(x\) is written \(\Phi_i(x)\), then Ohm's law&#x2014;the current equals the potential drop multiplied by the conductance&#x2014;implies that the <i>axial current</i> \(I_i(x)\) [mA] is given by (\(\sigma_i\) [S/cm] is the intracellular conductivity):
</p>
\begin{align}
    I_i(x) &= -\pi a^2 \sigma_i \frac{\Phi_i(x+\Delta x) -
\Phi_i(x)}{\Delta x} \nonumber \\
            &\xrightarrow[\Delta x \to 0]{ }  -\pi a^2 \sigma_i \frac{d \Phi_i(x)}{dx} \, . \label{eq:stat2}\tag{4}
\end{align}

<p>
Then the charge conservation implies that the membrane current density \(i_m(x)\) (positive for
an outgoing current) is given by:
</p>
\begin{align}
    I_i(x+\Delta x) - I_i(x) &= -i_m(x)\, \Delta{}x \nonumber \\
    \frac{d I_i(x)}{dx} &= -i_m(x). \label{eq:stat3}\tag{5}
\end{align}

<p>
Combining equation 4 and equation 5 we get: 
</p>
\begin{align}
    \label{eq:stat4}\tag{6}
    i_m(x) &= \pi a^2 \sigma_i \frac{d^2 \Phi_i(x)}{d x^2}\, .
\end{align}

<p>
Now, writing the membrane potential \(V_m = \Phi_i - \Phi_e\) we have: 
</p>
\begin{align}
    \label{eq:stat5}\tag{7}
    i_m(x) &=  \pi a^2 \sigma_i \frac{d^2 V_m(x)}{dx^2} \,.
\end{align}

<p>
This allows us to rewrite equation 2 as:
</p>
\begin{align}
    \label{eq:stat6}\tag{8}
    \Phi_e(X,Y,Z) =  \frac{a^2 \sigma_i}{4 \sigma_e} \int_{x_{min}}^{x_{max}} \frac{1}{\sqrt{(x-X)^2+Y^2+Z^2}}
    \frac{d^2 V_m(x)}{dx^2} dx \,.    
\end{align}

<p>
The quasi-static approximation (Plonsey, 1967, <i>The bulletin of mathematical biophysics</i> <b>29</b>:657-664; Nicholson and Freeman, 1975, <i>Journal of Neurophysiology</i> <b>38</b>: 356-368)&#x2014;that 
amounts to considering the extracellular medium as purely resistive&#x2014; leads to 
a more general, <b>time dependent</b>, version of equation 8:
</p>
\begin{align}
    \label{eq:stat7}\tag{9}
    \Phi_e(X,Y,Z,t) =  \frac{a^2 \sigma_i}{4 \sigma_e} \int_{x_{min}}^{x_{max}} \frac{1}{\sqrt{(x-X)^2+Y^2+Z^2}}
    \frac{\partial^2 V_m(x,t)}{\partial x^2} dx \,.    
\end{align}

<p>
<b>Notice that the derivation of equations 8 and 9  does not assume anything about the origin of the membrane potential 
non-uniformity.</b>
</p>

<p>
If the membrane potential deviation with respect to rest, \(\Delta{}V_m\), and its derivatives are null at the boundaries of the integration domain, then two rounds of integration by part give (with \(X=0\) and \(h = \sqrt{Y^2+Z^2}\)):
</p>
\begin{align}
    \label{eq:statPart}\tag{10}
    \Phi_e(h) =  \frac{a^2 \sigma_i}{4 \sigma_e} \int_{x_{min}}^{x_{max}} \left(\frac{3 u^2}{(u^2+h^2)^{5/2}} - \frac{1}{(u^2+h^2)^{3/2}}\right) \Delta{}V_m(u) du \, .
\end{align}

<p>
At that stage, in order to go further, we need an explicit expression or value for \(\Delta{}V_m\). We are going to solve numerically the H &amp; H equations for that.
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline13" class="outline-2">
<h2 id="orgheadline13"><span class="section-number-2">3</span> Numerical integration of the H &amp; H equation</h2>
<div class="outline-text-2" id="text-3">
<p>
We follow here the exposition of Tuckwell (1988) <i>Introduction to theoretical neurobiology. Volume 2.</i> CUP, pp 54-70<sup><a id="fnr.1" class="footref" href="#fn.1">1</a></sup>. We want to solve the following set of equations:
</p>

\begin{align}
    C_m \, \frac{\partial V_m}{\partial t} &= \frac{a \sigma_i}{2} \frac{\partial^2 V_m}{\partial x^2} + \overline{g}_K n^4 (V_K-V_m) + \overline{g}_{Na} m^3 h (V_{Na}-V_m) + g_l (V_l - V_m) + I_A \, , \label{eq:HH-PDE}\tag{11}\\
    \frac{\partial n}{\partial t} &= \alpha_n(V_m) (1-n) - \beta_n(V_m) n \, , \label{eq:HH-n}\tag{12}\\
    \frac{\partial m}{\partial t} &= \alpha_m(V_m) (1-m) - \beta_m(V_m) m \, , \label{eq:HH-m}\tag{13}\\
    \frac{\partial h}{\partial t} &= \alpha_h(V_m) (1-h) - \beta_h(V_m) h \, , \label{eq:HH-h}\tag{14}
\end{align}

<p>
where \(C_m\) is the membrane capacitance per unit area [\(\mu{}F/cm^2\)]; \(\overline{g}_K\), \(\overline{g}_{Na}\) and \(g_l\) are the potassium, sodium and leak conductances per unit area [mS/cm\(^2\)]; \(V_K\), \(V_{Na}\) and \(V_l\) are the potassium, sodium and leak currents reversal potentials [mV] and \(I_a\) is "externally" applied current per unit area [\(\mu{}A/cm^2\)] and all the \(\alpha\) and \(\beta\) functions are measured in [1/ms]. <b>You have to be careful here with the units since</b> \(\sigma_i\) <b>is usually given in [S/cm] leading to a first term on the right hand side of equation 11 in</b> [mA/cm\(^2\)] <b>while the left hand side as well as the remaining terms on the right hand side are in</b> [\(\mu{}A/cm^2\)]. 
</p>
</div>

<div id="outline-container-orgheadline8" class="outline-3">
<h3 id="orgheadline8"><span class="section-number-3">3.1</span> A standardized form for the non-linear reaction-diffusion equations</h3>
<div class="outline-text-3" id="text-3-1">
<p>
We will consider a <i>reaction-diffusion</i> system with the form:
</p>

\begin{align}
    \mathbf{u}_t = \mathbf{D} \, \mathbf{u}_{xx} + \mathbf{F}(\mathbf{u}) \, , \label{eq:reaction-diffusion}\tag{15}
\end{align}

<p>
where the \(t\) subscript stands for the partial derivative with respect to time, the \(xx\) subscripts stands for the second partial derivative with respect to position, \(\mathbf{u} = \left(u_1(x,t),\ldots,u_n(x,t)\right)^T \in \mathbb{R}^n\), \(\mathbf{D}\) is a diagonal \(n \times n\)  matrix of diffusion coefficients \(\left(D_1,\ldots,D_n\right)\) and \(\mathbf{F}(\cdot) = \left(F_1(\cdot),\ldots,F_n(\cdot)\right)^T\) is a vector-valued function. The corresponds with the above H &amp; H equations is obtained by setting: \(\mathbf{u} = \left(V_m,n,m,h\right)^T\); \(\left(D_1,D_2,D_3,D_4\right) = \left(\frac{a \sigma_i}{2 C_m},0,0,0\right)\), \(F_1(\mathbf{u}) = \left(\overline{g}_K n^4 (V_K-V_m) + \overline{g}_{Na} m^3 h (V_{Na}-V_m) + g_l (V_l - V_m) + I_A\right)/C_m\), \(F_2(\mathbf{u}) \equiv F_2(V_m,n)\), \(F_3(\mathbf{u}) \equiv F_3(V_m,m)\) and \(F_4(\mathbf{u}) \equiv F_4(V_m,h)\) are given by equations 12, 13 and 14.   
</p>
</div>

<div id="outline-container-orgheadline5" class="outline-4">
<h4 id="orgheadline5"><span class="section-number-4">3.1.1</span> The heat equation</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
Let us consider a simpler problem, the <i>heat equation</i>:
</p>

\begin{align}
    u_t = D \, u_{xx} \, , \label{eq:heat-equation}\tag{16}
\end{align}

<p>
where \(u(x,t)\) is a scalar. A numerical integration procedure is possible by <i>finite differencing</i>. Here, the heat equation (16) is replaced by a finite difference equation whose solution <i>approximates</i> the one of the heat equation. We discretize the \(x\) axis using \(m+1\) equally spaced points (with a step \(\Delta{}x\)) and the \(t\) axis using \(n+1\) equally spaced times (with a step \(\Delta{}t\)). We write the approximate solution as:
</p>

\begin{align}
    U_{i,j} = u(i \Delta{}x,j \Delta{}t) \quad i = 0,\ldots,m \; i = 0,\ldots,n \, . \label{eq:discrete-u}\tag{17}
\end{align}

<p>
The finite difference approximations of the required derivatives are:
</p>

\begin{align}
    u_t(x,t) &\approx \frac{U_{i,j+1}-U_{i,j}}{\Delta{}t} \, , \label{eq:u_t}\tag{18} \\
    u_x(x,t) &\approx \frac{U_{i+1,j}-U_{i,j}}{\Delta{}x} \, , \label{eq:u_x}\tag{19} \\
    u_{xx}(x,t) &\approx \frac{u_x(x,t)-u_x(x-\Delta{}x,t)}{\Delta{}x} \, , \nonumber \\
    &\approx \frac{U_{i+1,j}-2 \, U_{i,j} + U_{i-1,j}}{\Delta{}x^2} \, . \label{eq:u_xx}\tag{20} \\
\end{align}

<p>
The numerical integration of the heat equation with the finite difference equation is obtained by establishing a relation between the \(U_{i,j+1}\) and the \(U_{i,j}\). One methods approximates the second spatial derivative at \(t\) by the one at \(t+\Delta{}t\) giving the scheme:
</p>

\begin{align}
    \frac{U_{i,j+1}-U_{i,j}}{\Delta{}t} = \frac{D}{\Delta{}x^2} \left(U_{i+1,j+1}-2 \, U_{i,j+1} + U_{i-1,j+1}\right)\, . \label{eq:Ames-scheme}\tag{21} 
\end{align}

<p>
<a href="https://en.wikipedia.org/wiki/Crank%E2%80%93Nicolson_method">Crank and Nicolson</a> used the average of the approximations to the second space derivatives at the \(jth\) and \((j+1)th\) time points to get:
</p>

\begin{align}
    \frac{U_{i,j+1}-U_{i,j}}{\Delta{}t} = \frac{D}{2 \Delta{}x^2} \left(U_{i+1,j+1}-2 \, U_{i,j+1} + U_{i-1,j+1} + U_{i+1,j}-2 \, U_{i,j} + U_{i-1,j}\right)\, . \label{eq:Crank-Nicolson}\tag{22} 
\end{align}

<p>
More generally a weight factor \(\lambda\) can be used with weight \(\lambda\) for the \((j+1)th\) time points and weight \((1-\lambda)\) for the \(jth\) with \(0 \le \lambda \le 1\). Then with:
</p>

\begin{align}
    r \doteq \frac{D \Delta{}t}{\Delta{}x^2} \, , \label{eq:step-ratio}\tag{23} 
\end{align}

<p>
we have:
</p>

\begin{align}
    -r \lambda U_{i-1,j+1} + (1+2 r \lambda) U_{i,j+1} -r \lambda U_{i+1,j+1} = r (1-\lambda) U_{i-1,j} + \left(1-2 r (1-\lambda)\right) U_{i,j} + r (1-\lambda) U_{i+1,j}\, , \label{eq:general-Crank-Nicolson}\tag{23} 
\end{align}

<p>
where all the unknown terms in \(j+1\) are on the left side. Since \(i = 0,1,\ldots,m\) there are \(m+1\) equations with \(m+1\) unknown. This integration scheme is called <i>implicit</i> because a linear system must be solved to obtain the values of \(u(x,t)\) at the next time step. The system defined by equation 23 is <i>tridiagonal</i> and can be solved without matrix inversion. In <code>Python</code>, the <a href="http://docs.scipy.org/doc/scipy/reference/tutorial/linalg.html">scipy.linalg</a> sub-module provides the <a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.solve_banded.html#scipy.linalg.solve_banded">solve_banded</a> function to work efficiently with linear systems exhibiting a banded structure. 
</p>
</div>
</div>

<div id="outline-container-orgheadline6" class="outline-4">
<h4 id="orgheadline6"><span class="section-number-4">3.1.2</span> Adding the reaction term: Lee's method</h4>
<div class="outline-text-4" id="text-3-1-2">
<p>
We now add a <i>reaction term</i> \(F(u)\) to the scalar heat equation:
</p>

\begin{align}
    u_t = D \, u_{xx} + F(u) \, . \label{eq:heat-equation-plus-reaction}\tag{24}
\end{align}

<p>
In the Crank-Nicolson method the second space derivative is approximated by the average of its finite-difference approximations at time points \(j\) and \(j+1\). A similar estimate is needed for \(F(u)\); in other words we need \(F(U_{i,j+^1/_2})\) and we approximate \(U_{i,j+^1/_2}\) by:
</p>

\begin{align}
    U_{i,j+^1/_2} &\approx U_{i,j} + (U_{i,j} - U_{i,j-1})/2  \nonumber \\
    &\approx \frac{3}{2} U_{i,j} - \frac{1}{2} U_{i,j-1} \, . \label{eq:mid-point}\tag{25}
\end{align}

<p>
And Lees' modification of the Crank-Nicolson method gives the tridiagonal system (remember that \(\lambda\) in equation 23 equals \(^1/_2\) for the Crank-Nicolson method):
</p>

\begin{align}
    -\frac{r}{2} U_{i-1,j+1} + (1+r) U_{i,j+1} -\frac{r}{2} U_{i+1,j+1} = \frac{r}{2} U_{i-1,j} + (1-r) U_{i,j} + \frac{r}{2}U_{i+1,j} + \Delta{}t F\left(\frac{3}{2} U_{i,j} - \frac{1}{2} U_{i,j-1}\right)\, . \label{eq:Lees-method}\tag{26} 
\end{align}

<p>
Clearly this last equation can only be used if \(j>0\) so for \(j=0\) we use an <i>explicit</i> version (we use \(j\) instead of \(j+1\) in the right hand side of equation 21):
</p>

\begin{align}
    U_{i,1} = r \left(U_{i-1,0} -2 U_{i,0} + U_{i+1,0}\right) + \Delta{}t F\left(U_{i,0}\right) + U_{i,0}\, . \label{eq:Lees-method-explicit}\tag{27} 
\end{align}
</div>
</div>

<div id="outline-container-orgheadline7" class="outline-4">
<h4 id="orgheadline7"><span class="section-number-4">3.1.3</span> Boundary conditions</h4>
<div class="outline-text-4" id="text-3-1-3">
<p>
There is still one problem to consider before starting writing our code: the <i>boundary conditions</i>, that is what happens at the ends of the cable. There two "extreme" possibilities (and a third one in between the two). The first possibility consists in imposing the voltage at both ends, this leads to the <i>Dirichlet conditions</i>:
</p>

\begin{align}
    u(0,t) &= \alpha \, ,  \label{eq:Dirichlet-0}\tag{28} \\
    u(L,t) &= \beta   \, . \label{eq:Dirichlet-L}\tag{29}
\end{align}

<p>
The finite difference version is:
</p>

\begin{align}
    U_{0,j} &= \alpha \, , \quad j=0,1,\ldots  \, , \label{eq:Dirichlet-0-discrete}\tag{30} \\
    U_{m,j} &= \beta \, , \quad j=0,1,\ldots   \, . \label{eq:Dirichlet-L-discrete}\tag{31}
\end{align}

<p>
These conditions reduce the number of unknown in our linear system by 2, from \(m+1\) to \(m-1\) and correspond to voltage-clamping the ends of the cable.
</p>

<p>
The more common conditions in simulation studies are the <i>Neumann conditions</i> where the values of the space derivatives of the potential are imposed at the ends:
</p>

\begin{align}
    u_x(0,t) &= \alpha \, ,  \label{eq:Neumann-0}\tag{32} \\
    u_x(L,t) &= \beta   \, . \label{eq:Neumann-L}\tag{33}
\end{align}

<p>
The common values chosen are \(\alpha = \beta = 0\) often referred to as the "sealed ends" conditions&#x2014;the ones we are going to choose in our numerical implementation. To get the finite difference version, a quick solution would be using \(u_x(x,t) \approx \left(U_{i+1,j}-U_{i,j}\right) / \Delta{}x\), but we can do better&#x2014;in term of the approximation of the space derivative by its finite difference version at fixed \(\Delta{}x\) using:
</p>

\begin{align}
    u_x(i \Delta{}x,j \Delta{}t) &\approx \frac{U_{i+1,j} - U_{i-1,j}}{2 \Delta{}x}   \, . \label{eq:central-difference}\tag{34}
\end{align}

<p>
Can you see why? Then the Neumann conditions become:
</p>

\begin{align}
    U_{-1,j} &= -2 \alpha \Delta{}x + U_{1,j}\, ,  \label{eq:Neumann-0-discrete}\tag{35} \\
    U_{m+1,j} &= 2 \beta \Delta{}x + U_{m-1,j}  \, . \label{eq:Neumann-L-discrete}\tag{36}
\end{align}

<p>
This amounts to introducing "false boundaries" and substituting 35 in 26, the first equation becomes (for \(j>0\)):
</p>

\begin{align}
     (1+r) U_{0,j+1} -r U_{1,j+1} = - 2 r \alpha \Delta{}x + (1-r) U_{0,j} + r U_{1,j} + \Delta{}t F\left(\frac{3}{2} U_{0,j} - \frac{1}{2} U_{0,j-1}\right)\, . \label{eq:Lees-left}\tag{37} 
\end{align}

<p>
At \(j=0\) the substitution in equation 27 leads to:
</p>

\begin{align}
     U_{0,1} = 2 r \left(U_{1,0} - U_{0,0} - \alpha \Delta{}x\right) + \Delta{}t F\left(U_{0,0}\right) + U_{0,0}\, . \label{eq:Lees-left-at-0}\tag{38} 
\end{align}

<p>
At the other end we get for \(j>0\):
</p>

\begin{align}
     -r U_{m-1,j+1} + (1+r) U_{m,j+1} = 2 r \beta \Delta{}x + r U_{m-1,j} + (1-r) U_{m,j} + \Delta{}t F\left(\frac{3}{2} U_{m,j} - \frac{1}{2} U_{m,j-1}\right)\, , \label{eq:Lees-right}\tag{39} 
\end{align}

<p>
while for \(j=0\) we have:
</p>

\begin{align}
     U_{m,1} = 2 r \left(U_{m-1,0} - U_{m,0} + \beta \Delta{}x\right) + \Delta{}t F\left(U_{m,0}\right) + U_{m,0}\, . \label{eq:Lees-right-at-0}\tag{40} 
\end{align}
</div>
</div>
</div>


<div id="outline-container-orgheadline9" class="outline-3">
<h3 id="orgheadline9"><span class="section-number-3">3.2</span> Python code doing the job</h3>
<div class="outline-text-3" id="text-3-2">
<p>
We are going to solve the standard H &amp; H model using the Neumann boundary conditions with \(\alpha = \beta = 0\) ("sealed ends"). We start by an <code>IPython</code> session&#x2014;but it wokrs as well with a classical <code>Python</code> session&#x2014;loading the two main modules we are going on a regular basis, <code>numpy</code> and <code>pylab</code> a sub-module of <code>matplotlib</code>:
</p>

<div class="org-src-container">

<pre class="src src-python">import numpy as np
import matplotlib.pylab as plt
plt.ion()
#%matplotlib inline
plt.style.use('ggplot')
</pre>
</div>

<p>
The three last commands give us <i>interactive</i> graphics (<code>plt.ion</code>) or <i>inline</i> graphics when using the <code>jupyter notebook</code> (in that case, comment the previous line with "#" and uncomment the following one) and a nicer default style for the graphs (<code>plt.style.use('ggplot')</code>). We then assign a few variables considering an axon with a radius \(a\) of 1 \(\mu{}m\) that is \(10^{-4}\) cm (for quantitative data on CNS axons diameters, see <a href="http://www.jneurosci.org/content/32/2/626.abstract">Perge et al (2013)</a>):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock1">a = 1e-4
</pre>
</div>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock2">Cm = 1.0 # H &amp; H 1952 [μF / cm^2]
rho = 35.4 # H &amp; H 1952, rho is the inverse of σi [Ω cm]
D = a / (2.0 * rho * Cm) # the "Diffusion" constant
D
</pre>
</div>

<pre class="example">
1.4124293785310736e-06
</pre>

<p>
Notice that with this choice of units <code>D</code> is measured in cm\(^2\) / \(\mu{}s\). We define next, for each activation variable, \(n, m, h\) the \(\alpha(v)\) and \(\beta(v)\) functions&#x2014;where the formal parameter \(v\) stands for the <b>deviation of the membrane voltage with respect to rest</b>&#x2014;as well as a function returning the steady-state value of the variable at a given voltage. We start with the \(n\) activation variable&#x2014;the <code>numpy</code> module must have been previously imported with the alias <code>np</code> (<code>import numpy as np</code>)&#x2014;:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock3">def alpha_n(v):
    if np.abs(v-10.0) &lt; 1e-10:
        return 0.1
    else:
        return 0.01*(10.0 - v)/(np.exp((10.0-v)/10.0)-1.0)
def beta_n(v):
    return 0.125*np.exp(-0.0125*v)
n_inf = np.vectorize(lambda v: alpha_n(v)/(alpha_n(v) + beta_n(v)))
</pre>
</div>

<p>
Notice that we took care of the special case \(v=10\) using the limit to avoid the undefined expression \(0/0\). The <code>n_inf</code> function has been defined in a <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.vectorize.html#numpy.vectorize">vectorized form</a> since our definition of <code>alpha_n</code> works only with scalar arguments. Having defined these functions it is always a good idea to make a couple of graphs to make sure that we did things properly (we should get figures 4 and 5, p 511 of H &amp; H 1952; <i>don't forget that the membrane voltage convention at that time was the opposite of the one now used</i>):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock4">vv = np.linspace(-50,110,201)
plt.plot(vv,np.vectorize(alpha_n)(vv),lw=2)
plt.plot(vv,np.vectorize(beta_n)(vv),lw=2)
plt.plot(vv,n_inf(vv),lw=2)
</pre>
</div>


<div class="figure">
<p><img src="figsL1/n_activation.png" alt="n_activation.png" />
</p>
<p><span class="figure-number">Figure 1:</span> \(\alpha_n\) (red), \(\beta_n\) (blue) and \(n_{\infty}\) (violet) as a function of the membrane voltage deviation with respect to rest.</p>
</div>

<p>
We can now define function <code>F_n</code> corresponding to the \(F_2\) of equation 15 whose expression is given by equation 12; this function takes two formal parameters: the membrane potential (deviation) <code>v</code> and the activation variable <code>n</code>:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock5">def F_n(v,n):
    if np.abs(v-10.0) &lt; 1e-10:
        alpha = 0.1
    else:
        alpha = 0.01*(10.0 - v)/(np.exp((10.0-v)/10.0)-1.0)
    beta = 0.125*np.exp(-0.0125*v)
    return alpha*(1-n)-beta*n
vF_n = np.vectorize(F_n)
</pre>
</div>

<p>
It is again a good idea to use these newly defined functions to make sure that nothing "too pathological" happens:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock6">F_n(20,0.6)
</pre>
</div>

<pre class="example">
0.0048690095444177128
</pre>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock7">vF_n([-10,0,10,20,30],[0.1,0.2,0.3,0.4,0.5])
</pre>
</div>

<pre class="example">
array([ 0.01400882,  0.02155814,  0.03690637,  0.05597856,  0.07269618])
</pre>

<p>
Notice that we "redefine" <code>alpha_n</code> and <code>beta_n</code> inside <code>F_n</code>, this is to gain execution time by avoiding function calls. We also define a vectorized version <code>vF_n</code> that will take two formal parameters, <code>v</code> and <code>n</code>, that can be vectors. We proceed in the same way with the \(m\) activation variable:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock8">def alpha_m(v):
    if np.abs(v-25.0) &lt; 1e-10:
        return 1.0
    else:
        return 0.1*(25.0 - v)/(np.exp((25.0 - v)/10.0)-1.0)
def beta_m(v):
        return 4*np.exp(-.0555*v)
m_inf = np.vectorize(lambda v: alpha_m(v)/(alpha_m(v) + beta_m(v)))
</pre>
</div>

<p>
The graphs (not shown) giving figures 7 and 8 pp 515-516 are obtained with:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock9">vv = np.linspace(-50,110,201)
plt.plot(vv,np.vectorize(alpha_m)(vv),lw=2)
plt.plot(vv,np.vectorize(beta_m)(vv),lw=2)
plt.plot(vv,m_inf(vv)*10,lw=2)
plt.xlim(-10,110)
plt.ylim(0,10)
</pre>
</div>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock10">def F_m(v,m):
    if np.abs(v-25.0) &lt; 1e-10:
        alpha = 1.0
    else:
        alpha =  0.1*(25.0 - v)/(np.exp((25.0 - v)/10.0)-1.0)
    beta = 4*np.exp(-.0555*v)
    return alpha*(1-m)-beta*m
vF_m = np.vectorize(F_m)
</pre>
</div>

<p>
A quick check gives:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock11">vF_m([-10,0,10,20,30],[0.1,0.2,0.3,0.4,0.5])
</pre>
</div>

<pre class="example">
array([-0.59869277, -0.62114902, -0.38730895, -0.06484611,  0.2569922 ])
</pre>

<p>
And for the \(h\) activation variable:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock12">def alpha_h(v):
    return 0.07*np.exp(-0.05*v)
def beta_h(v):
    return 1.0/(np.exp((30.0 - v)/10.0) + 1.0)
def h_inf(v):
    return alpha_h(v)/(alpha_h(v) + beta_h(v))
</pre>
</div>

<p>
Notice that since <code>alpha_h</code> is already (implicitly) vectorized, there is no need to use <code>np.vectorize</code> when defining function <code>h_inf</code>. The graphs (not shown) giving figures 9 and 10 pp 517-518 are obtained with:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock13">vv = np.linspace(-50,110,201)
plt.plot(vv,np.vectorize(alpha_h)(vv),lw=2)
plt.plot(vv,np.vectorize(beta_h)(vv),lw=2)
plt.plot(vv,h_inf(vv),lw=2)
</pre>
</div>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock14">def F_h(v,h):
    return 0.07*np.exp(-0.05*v)*(1-h)-1.0/(np.exp((30.0 - v)/10.0) + 1.0)*h
vF_h = np.vectorize(F_h)
</pre>
</div>

<p>
A quick check gives:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock15">vF_h([-10,0,10,20,30],[0.1,0.2,0.3,0.4,0.5])
</pre>
</div>

<pre class="example">
array([ 0.10207082,  0.04651483, -0.00604087, -0.09212563, -0.24219044])
</pre>

<p>
We define next <code>F_V</code> corresponding to the \(F_1\) of equation 15. This function takes 5 formal parameters: <code>v</code>, <code>n</code>, <code>m</code>, <code>h</code> and <code>Ia</code> the injected current. The maximal conductances [mS / cm\(^2\)] and reversal potentials [mV] from H &amp; H (1952) are assigned to local variables in the function. A vectorized version is also defined:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock16">def F_V(v,n,m,h,Ia):
    GNa, GK, GL = 120.0, 36.0, 0.3 # H &amp; H 1952
    ENa, EK, EL = 115.0, -12.0, 10.5987 # H &amp; H 1952
    return (GK*n**4*(EK-v)+GNa*m**3*h*(ENa-v)+GL*(EL-v)+Ia)/Cm
vF_V = np.vectorize(F_V)
</pre>
</div>

<p>
We can now make a first (explicit) step. We are going to consider a thin cable with a 1 \(\mu{}m\) radius and we start by getting its length constant: \(\lambda = \sqrt{a/2 \rho_i \sigma_m}\). We already set \(\rho_i = 35.4\) [\(\Omega{}\) cm], we get the resting value of \(\sigma_m\) [S / cm\(^2\)] by getting the activation variables values at resting level (don't forget that the conductance densities given by H &amp; H are in [mS]):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock17">sigma_m_rest = (36*n_inf(0)**4+120*m_inf(0)**3*h_inf(0)+0.3)/1000
sigma_m_rest
</pre>
</div>

<pre class="example">
0.00067725364844574128
</pre>

<p>
This gives us a length constant at rest in cm:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock18">lambda_rest = np.sqrt(1e-4/2/rho/sigma_m_rest)
lambda_rest
</pre>
</div>

<pre class="example">
0.045667548060889344
</pre>

<p>
So our length constant is roughly 500 \(\mu{}m\). We will pick a space discretization step of 50 \(\mu{}m\) (5 \(\times 10^{-3}\) cm) equal to a tenth of the length constant and choose a cable length of 20000 \(\mu{}m\) (2 cm), forty times the length constant. We then choose our time discretization step such that the value \(r\) defined by equation 23 is not too large, say 2 (the reason for using an implicit method like the <a href="https://en.wikipedia.org/wiki/Crank%E2%80%93Nicolson_method">Crank-Nicolson</a> method instead of an explicit one in that the latter is stable only if \(r \le 0.5\)). That gives us for \(\Delta{}t\) (remember that our <code>D</code> above is in cm\(^2\) / \(\mu{}s\) and we want a result in \(ms\)):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock19">Delta_x = 5e-3
r = 2
Delta_t = r*Delta_x**2/D/1000
Delta_t
</pre>
</div>

<pre class="example">
0.0354
</pre>

<p>
To be on the safe side, we will pick a \(\Delta{}t\) of 0.025 ms:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock20">Delta_t = 0.025
</pre>
</div>

<p>
We now need 4 vectors containing the membrane voltage (deviation) and the value of each activation variable at each discrete location along our cable:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock21">L = 2
M = L/Delta_x
v_0 = np.zeros(M+1)
n_0 = np.ones(M+1)*n_inf(0)
m_0 = np.ones(M+1)*m_inf(0)
h_0 = np.ones(M+1)*h_inf(0)
</pre>
</div>

<p>
We also need a vector of the same length with the injected current density at each point along the axon:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock22">Ia_0 = np.zeros(M+1)
Ia_0[0] = 1000.0
</pre>
</div>

<p>
We can now define a function performing a single time step with the explicit method using equations 27, 38 and 40:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock23">def explicit_step(v,n,m,h,Ia):
    v_new = np.copy(v)
    n_new = np.copy(n)
    m_new = np.copy(m)
    h_new = np.copy(h)
    reaction_term = Delta_t * vF_V(v,n,m,h,Ia)
    diffusion_term = np.zeros(len(v))
    diffusion_term[1:-1] = (v[0:-2]-2*v[1:-1]+v[2:])*r
    diffusion_term[0] = 2*r*(v[1]-v[0])
    diffusion_term[-1] = 2*r*(v[-2]-v[-1])
    v_new += diffusion_term + reaction_term
    n_new += Delta_t*vF_n(v,n)
    m_new += Delta_t*vF_m(v,m)
    h_new += Delta_t*vF_h(v,h)
    return v_new,n_new,m_new,h_new
</pre>
</div>

<p>
We perform one explicit step with:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock24">v_1, n_1, m_1, h_1 = explicit_step(v_0,n_0,m_0,h_0,Ia_0)
</pre>
</div>

<p>
The general time step using Lees' method is an implicit one and requires a banded matrix (containing the voltage factor on the right hand side of equations 28, 37 and 39) to be define that's what do now:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock25">A = np.zeros((3,M+1))
A[0,2:] = -r/2.0 # upper diagonal
A[0,1] = -r # upper diagonal
A[1,:] = 1.0 + r # diagonal
A[2,:-3] = -r/2.0 # lower diagonal
A[2,-2] = -r # lower diagonal
</pre>
</div>

<p>
We now define a function doing one Lees' step. The function needs the present and previous (or old) values of v, n, m and h as well as Ia. The function assumes that the banded matrix <code>A</code> above is already available in the environment and loads function <code>solve_banded</code> from <code>scipy.linalg</code> sub-module:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock26">def lees_step(v_old,n_old,m_old,h_old,Ia_old,
              v_present,n_present,m_present,h_present,Ia_present):
    from scipy.linalg import solve_banded
    v_extra = 1.5*v_present-0.5*v_old # extrapolated mid-point value
    n_extra = 1.5*n_present-0.5*n_old # extrapolated mid-point value
    m_extra = 1.5*m_present-0.5*m_old # extrapolated mid-point value          
    h_extra = 1.5*h_present-0.5*h_old # extrapolated mid-point value
    Ia_extra = 1.5*Ia_present-0.5*Ia_old # extrapolated mid-point value
    n_new = np.copy(n_present)+Delta_t*vF_n(v_extra,n_extra)
    m_new = np.copy(m_present)+Delta_t*vF_m(v_extra,m_extra)
    h_new = np.copy(h_present)+Delta_t*vF_h(v_extra,h_extra)
    reaction_term = Delta_t*vF_V(v_extra,n_extra,m_extra,h_extra,Ia_extra)
    diffusion_term = (1-r)*np.copy(v_present)
    diffusion_term[1:-1] += (v_present[0:-2] + v_present[2:])*r/2.0
    diffusion_term[0] += r*v_present[1]
    diffusion_term[-1] += r*v_present[-2]
    v_new = solve_banded((1,1),A,reaction_term+diffusion_term)
    return v_new, n_new, m_new, h_new
</pre>
</div>

<p>
We make one step with:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock27">v_2,n_2,m_2,h_2 = lees_step(v_0,n_0,m_0,h_0,Ia_0,v_1,n_1,m_1,h_1,Ia_0)
</pre>
</div>

<p>
Now 2000 more steps stopping the stimulation after 2 ms or 80 steps (this take a few seconds on my slow laptop):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock28">v_M = np.zeros((2002,int(M+1)))
v_M[0] = v_0
v_M[1] = v_1
n_M = np.zeros((2002,int(M+1)))
n_M[0] = n_0
n_M[1] = n_1
m_M = np.zeros((2002,int(M+1)))
m_M[0] = m_0
m_M[1] = m_1
h_M = np.zeros((2002,int(M+1)))
h_M[0] = h_0
h_M[1] = h_1
for i in range(2,2002):
    if i &lt; 80:
        v_M[i,:],n_M[i,:],m_M[i,:],h_M[i,:] = lees_step(v_M[i-2,:],n_M[i-2,:],m_M[i-2,:],h_M[i-2,:],Ia_0,
                                                        v_M[i-1,:],n_M[i-1,:],m_M[i-1,:],h_M[i-1,:],Ia_0)
    if i == 80:
        v_M[i,:],n_M[i,:],m_M[i,:],h_M[i,:] = lees_step(v_M[i-2,:],n_M[i-2,:],m_M[i-2,:],h_M[i-2,:],Ia_0,
                                                        v_M[i-1,:],n_M[i-1,:],m_M[i-1,:],h_M[i-1,:],0)
    if i &gt; 80:
        v_M[i,:],n_M[i,:],m_M[i,:],h_M[i,:] = lees_step(v_M[i-2,:],n_M[i-2,:],m_M[i-2,:],h_M[i-2,:],0,
                                                        v_M[i-1,:],n_M[i-1,:],m_M[i-1,:],h_M[i-1,:],0)
</pre>
</div>

<p>
We can graph the spatial profile of the membrane potential deviation at different times like every 40 time steps or every ms for the first 10 ms:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock29">xx = np.arange(0,M+1)*5e-3
for i in range(0,442,40):
    plt.plot(xx,v_M[i],color='black',lw=2)
plt.xlabel('Position (cm)')
plt.ylabel(r'$\Delta{}V_m$ (mV)')
</pre>
</div>


<div class="figure">
<p><img src="figsL1/voltage_spatial_profile_evolution.png" alt="voltage_spatial_profile_evolution.png" />
</p>
<p><span class="figure-number">Figure 2:</span> Spatial profile of the membrane voltage at every ms for 11 ms (from left to right).</p>
</div>

<p>
Before going further, writing a couple of functions abstracting the many pieces of code we have just used seems a good idea.
</p>
</div>
</div>

<div id="outline-container-orgheadline10" class="outline-3">
<h3 id="orgheadline10"><span class="section-number-3">3.3</span> Some functions definitions</h3>
<div class="outline-text-3" id="text-3-3">
<p>
We want a function that takes axon geometrical parameters&#x2014;radius and length&#x2014;, simulation time, space and time steps and applied current as formal parameters and for which all the other parameters (reversal potentials, conductances, etc) are set. If we want to be able to change one or several of these other parameters, it is worth exploiting one of the great features of <a href="https://en.wikipedia.org/wiki/Python_syntax_and_semantics">Python</a>: is supports <a href="https://en.wikipedia.org/wiki/Closure_(computer_programming)">lexical closures</a>; and that allows us to write functions returning other functions. That's what we will do here (remark that all the functions previously defined are reused directly, except <code>F_V</code> since the necessary parameters are in the lexical scope of the function definition). In order to compare our code output with cases published in the literature like <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1368016/">Cooley and Dodge (1966)</a> we add a <i>temperature</i>, <code>T</code>, formal parameter. The H &amp; H model parameters we used til now are valid at 6.3°C and we implement the temperature dependence of the rate equations given by H &amp; H, Cooley and Dodge, Tuckwell, etc&#x2026;  
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock30">def mk_cable_fcts(Cm = 1.0,
                  rho = 35.4, 
                  GNa = 120.0,
                  ENa = 115.0,
                  GK = 36.0,
                  EK = -12.0,
                  GL = 0.3,
                  EL = 10.5987,
                  T = 6.3):
    """Returns functions for H &amp; H axon simulation
    
    Formal parameters:
    Cm: a double, the membrane capacitance [μF / cm^2]
    rho: a double, intracellular resistivity [Ω cm]
    GNa: sodium conductance density [mS / cm^2]
    ENa: sodium reversal potential [mV]
    GK: potassium conductance density [mS / cm^2]
    EK: potassium reversal potential [mV]
    GL: leak conductance density [mS / cm^2]
    EL: leak reversal potential [mV]
    T: a positive double, the temperature in Celsius

    Returns:
    D_fct: a function of the axon radius in cm that
           returns the "diffusion coefficient"
    r_fct: a function of the radius, the space and time steps
           that returns the value of r in equation 23
    lambda_fct: a function of the radius that returns the
                length constant
    sim_with_lees: a function of the radius, the length, the steps
                   the injected current that performs the simulation
    """
    import numpy as np
    Q = 3**((T-6.3)/10)
    def D_fct(a):
        return a / (2.0 * rho * Cm)
    def alpha_n(v):
        if np.abs(v-10.0) &lt; 1e-10:
            return 0.1
        else:
            return 0.01*(10.0 - v)/(np.exp((10.0-v)/10.0)-1.0)
    def beta_n(v):
        return 0.125*np.exp(-0.0125*v)
    n_inf = np.vectorize(lambda v: alpha_n(v)/(alpha_n(v) + beta_n(v)))
    def F_n(v,n):
        if np.abs(v-10.0) &lt; 1e-10:
            alpha = 0.1
        else:
            alpha = 0.01*(10.0 - v)/(np.exp((10.0-v)/10.0)-1.0)
        beta = 0.125*np.exp(-0.0125*v)
        return (alpha*(1-n)-beta*n)*Q
    vF_n = np.vectorize(F_n)     
    def alpha_m(v):
        if np.abs(v-25.0) &lt; 1e-10:
            return 1.0
        else:
            return 0.1*(25.0 - v)/(np.exp((25.0 - v)/10.0)-1.0)
    def beta_m(v):
        return 4*np.exp(-.0555*v)
    m_inf = np.vectorize(lambda v: alpha_m(v)/(alpha_m(v) + beta_m(v)))
    def F_m(v,m):
        if np.abs(v-25.0) &lt; 1e-10:
            alpha = 1.0
        else:
            alpha =  0.1*(25.0 - v)/(np.exp((25.0 - v)/10.0)-1.0)
        beta = 4*np.exp(-.0555*v)
        return (alpha*(1-m)-beta*m)*Q
    vF_m = np.vectorize(F_m)
    def alpha_h(v):
        return 0.07*np.exp(-0.05*v)
    def beta_h(v):
        return 1.0/(np.exp((30.0 - v)/10.0) + 1.0)
    def h_inf(v):
        return alpha_h(v)/(alpha_h(v) + beta_h(v))
    def F_h(v,h):
        return Q*(0.07*np.exp(-0.05*v)*(1-h)-1.0/(np.exp((30.0 - v)/10.0) + 1.0)*h)
    vF_h = np.vectorize(F_h)
    def F_V(v,n,m,h,Ia):
        return (GK*n**4*(EK-v)+GNa*m**3*h*(ENa-v)+GL*(EL-v)+Ia)/Cm
    vF_V = np.vectorize(F_V)
    def lambda_fct(a):
        sigma_m_rest = (GK*n_inf(0)**4+GNa*m_inf(0)**3*h_inf(0)+GL)/1000
        return np.sqrt(a/2/rho/sigma_m_rest)
    def r_fct(a,Delta_x,Delta_t):
        return D_fct(a)*Delta_t*1000/Delta_x**2
    def sim_with_lees(a,L,duration,
                      Delta_x,Delta_t,
                      Ia_amp, Ia_duration):
        def explicit_step(v,n,m,h,Ia):
            v_new = np.copy(v)
            n_new = np.copy(n)
            m_new = np.copy(m)
            h_new = np.copy(h)
            reaction_term = Delta_t * vF_V(v,n,m,h,Ia)
            diffusion_term = np.zeros(len(v))
            diffusion_term[1:-1] = (v[0:-2]-2*v[1:-1]+v[2:])*r
            diffusion_term[0] = 2*r*(v[1]-v[0])
            diffusion_term[-1] = 2*r*(v[-2]-v[-1])
            v_new += diffusion_term + reaction_term
            n_new += Delta_t*vF_n(v,n)
            m_new += Delta_t*vF_m(v,m)
            h_new += Delta_t*vF_h(v,h)
            return v_new,n_new,m_new,h_new
        def lees_step(v_old,n_old,m_old,h_old,Ia_old,
                      v_present,n_present,m_present,h_present,Ia_present):
            from scipy.linalg import solve_banded
            v_extra = 1.5*v_present-0.5*v_old # extrapolated mid-point value
            n_extra = 1.5*n_present-0.5*n_old # extrapolated mid-point value
            m_extra = 1.5*m_present-0.5*m_old # extrapolated mid-point value          
            h_extra = 1.5*h_present-0.5*h_old # extrapolated mid-point value
            Ia_extra = 1.5*Ia_present-0.5*Ia_old # extrapolated mid-point value
            n_new = np.copy(n_present)+Delta_t*vF_n(v_extra,n_extra)
            m_new = np.copy(m_present)+Delta_t*vF_m(v_extra,m_extra)
            h_new = np.copy(h_present)+Delta_t*vF_h(v_extra,h_extra)
            reaction_term = Delta_t*vF_V(v_extra,n_extra,m_extra,h_extra,Ia_extra)
            diffusion_term = (1-r)*np.copy(v_present)
            diffusion_term[1:-1] += (v_present[0:-2] + v_present[2:])*r/2.0
            diffusion_term[0] += r*v_present[1]
            diffusion_term[-1] += r*v_present[-2]
            v_new = solve_banded((1,1),A,reaction_term+diffusion_term)
            return v_new, n_new, m_new, h_new
        r = r_fct(a,Delta_x,Delta_t)
        M = int(np.ceil(L/Delta_x))
        N = int(np.ceil(duration/Delta_t))
        Na = int(np.ceil(Ia_duration/Delta_t))
        v_0 = np.zeros(M+1)
        n_0 = np.ones(M+1)*n_inf(0)
        m_0 = np.ones(M+1)*m_inf(0)
        h_0 = np.ones(M+1)*h_inf(0)
        Ia_0 = np.zeros(M+1)
        Ia_0[0] = Ia_amp
        v_1, n_1, m_1, h_1 = explicit_step(v_0,n_0,m_0,h_0,Ia_0)
        A = np.zeros((3,M+1))
        A[0,2:] = -r/2.0 # upper diagonal
        A[0,1] = -r # upper diagonal
        A[1,:] = 1.0 + r # diagonal
        A[2,:-3] = -r/2.0 # lower diagonal
        A[2,-2] = -r # lower diagonal
        v_M = np.zeros((N,int(M+1)))
        v_M[0] = v_0
        v_M[1] = v_1
        n_M = np.zeros((N,int(M+1)))
        n_M[0] = n_0
        n_M[1] = n_1
        m_M = np.zeros((N,int(M+1)))
        m_M[0] = m_0
        m_M[1] = m_1
        h_M = np.zeros((N,int(M+1)))
        h_M[0] = h_0
        h_M[1] = h_1
        for i in range(2,N):
            if i &lt; Na:
                v_M[i,:],n_M[i,:],m_M[i,:],h_M[i,:] = lees_step(v_M[i-2,:],n_M[i-2,:],m_M[i-2,:],h_M[i-2,:],Ia_0,
                                                                v_M[i-1,:],n_M[i-1,:],m_M[i-1,:],h_M[i-1,:],Ia_0)
            if i == Na:
                v_M[i,:],n_M[i,:],m_M[i,:],h_M[i,:] = lees_step(v_M[i-2,:],n_M[i-2,:],m_M[i-2,:],h_M[i-2,:],Ia_0,
                                                                v_M[i-1,:],n_M[i-1,:],m_M[i-1,:],h_M[i-1,:],0)
            if i &gt; Na:
                v_M[i,:],n_M[i,:],m_M[i,:],h_M[i,:] = lees_step(v_M[i-2,:],n_M[i-2,:],m_M[i-2,:],h_M[i-2,:],0,
                                                                v_M[i-1,:],n_M[i-1,:],m_M[i-1,:],h_M[i-1,:],0)
        return v_M,n_M,m_M,h_M
    return D_fct, r_fct, lambda_fct, sim_with_lees
</pre>
</div>

<p>
Once this kind of function has been defined <b>the first thing to do</b> is to check that it gives the same results as we got before doing the job step by step:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock31">D1,r1,lambda1,sim1 = mk_cable_fcts()
D1(1e-4)
r1(1e-4,5e-3,0.025)
v1,n1,m1,h1 = sim1(1e-4,2,20,5e-3,0.025,1000,2)
for i in range(0,442,40):
    plt.plot(v1[i],color='black',lw=2)
</pre>
</div>

<p>
The results are not shown since they are identical to the previous ones but you are invited to check for yourself.
</p>
</div>
</div>

<div id="outline-container-orgheadline11" class="outline-3">
<h3 id="orgheadline11"><span class="section-number-3">3.4</span> Checking against Cooley and Dodge (1966) results</h3>
<div class="outline-text-3" id="text-3-4">
<p>
<a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1368016/">Cooley and Dodge (1966) </a>were the first to numerically solve the "full" H &amp; H model&#x2014;the one specified by equations 11-14&#x2014;and we will now reproduce their figure 2 (we get slightly different results since our stimulation is not exactly the same):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock32">D_cd,r_cd,lambda_cd,sim_cd = mk_cable_fcts(rho=34.5,EL=10.598,T=18.5)
v_cd,n_cd,m_cd,h_cd = sim_cd(0.0238,7,10,0.025,0.001,2500,0.2)
</pre>
</div>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock33">plt.subplot(211)
xx = np.arange(v_cd.shape[1])*0.025
plt.plot(xx,v_cd[200,:],color='black',lw=2)
plt.plot(xx,v_cd[500,:],color='black',lw=2)
plt.plot(xx,v_cd[1000,:],color='black',lw=2)
plt.plot(xx,v_cd[2000,:],color='black',lw=2)
plt.plot(xx,v_cd[3000,:],color='black',lw=2)
plt.xlim(0,7)
plt.xlabel('Position (cm)')
plt.ylabel(r'$\Delta{}V_m$ (mV)')
plt.subplot(212)
tt = np.arange(v_cd.shape[0])*0.001
plt.plot(tt,v_cd[:,0],color='black',lw=2)
plt.plot(tt,v_cd[:,40],color='black',lw=2)
plt.plot(tt,v_cd[:,80],color='black',lw=2)
plt.plot(tt,v_cd[:,120],color='black',lw=2)
plt.xlim(0,3.5)
plt.xlabel('Time (ms)')
plt.ylabel(r'$\Delta{}V_m$ (mV)')
</pre>
</div>


<div class="figure">
<p><img src="figsL1/Cooley_and_Dodge_1966_Fig2_replicate.png" alt="Cooley_and_Dodge_1966_Fig2_replicate.png" />
</p>
<p><span class="figure-number">Figure 3:</span> Replication of figure 2 from Cooley and Dodge (1966). Top: the voltage space profiles are shown, from left to right at 0.2, 0.5, 1, 2 and 3 ms. Bottom: the voltage time profiles are shown from left to right at 0, 1, 2 and 3 cm.</p>
</div>

<p>
We get a speed [m/s] of:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock34">0.025*(np.argmax(v_cd[3000,:])-np.argmax(v_cd[2000,:]))*10
</pre>
</div>

<pre class="example">
19.0
</pre>

<p>
with a precision of 25 cm/S that is compatible with the results reported in their table 1 (p 591).
</p>
</div>
</div>

<div id="outline-container-orgheadline12" class="outline-3">
<h3 id="orgheadline12"><span class="section-number-3">3.5</span> Checking against the traveling wave solution</h3>
<div class="outline-text-3" id="text-3-5">
<p>
As we mentioned in the introduction, Hodgkin and Huxley did not explore numerically their "full" model but a particular solution of it: the traveling wave. Their reasoning was that is their full model was correct, the action potential&#x2014;a wave propagating at a constant speed without deformation&#x2014;should be one of its solutions. They therefore considered the membrane potential as a function of time observed at an arbitrary location chosen as the origin, \(x=0\), far enough from both ends of the axon. Then, writing \(V_0(t)\) the time course of the membrane potential observed when the action potential goes through the origin, and assuming a (constant) propagation speed, \(u\), they could write the general solution of their model as: \(V(x,t) = V_0(t-x/u)\), since the potential observed at location \(x\) at time \(t\) should be the one observed at the origin \(x/u\) seconds before. Then, writing \(z = t - x/u\) we have:
</p>

\begin{align}
     \frac{\partial V}{\partial t} = \frac{d V_0}{d z}\, , \label{eq:Vt-as-Vz}\tag{41} 
\end{align}

\begin{align}
     \frac{\partial V}{\partial x} = - \frac{1}{u} \frac{d V_0}{d z}\, , \label{eq:Vx-as-Vz}\tag{42} 
\end{align}

\begin{align}
     \frac{\partial^2 V}{\partial x^2} =  \frac{1}{u^2} \frac{d^2 V_0}{d z^2}\, . \label{eq:Vxx-as-Vz}\tag{43} 
\end{align}

<p>
The traveling wave version of equation 11 is then:
</p>

\begin{align}
     \frac{d V_0}{d z} =  \frac{D}{u^2} \frac{d^2 V_0}{d z^2} + \left(\overline{g}_K n^4 (V_K-V_0) + \overline{g}_{Na} m^3 h (V_{Na}-V_0) + g_l (V_l - V_0)\right)/ Cm \, , \label{eq:traveling-wave}\tag{44} 
\end{align}

<p>
where \(D = \frac{a \sigma_i}{2 C_m}\) like before. If the speed \(u\) is known, this (set of) ODE(s) can be solved for \(V_0\). The game is then to find such a \(u\) for which the computed solution does not diverge (this is done by a tedious trial an error approach). Here is how it can be done using the ODE solvers of <code>Python</code>. We start by defining a "constructor" function (giving the Cooley and Dodge values as default):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock35">def mk_travel_wave(a = 0.0238,
                   Cm = 1.0,
                   rho = 34.5, 
                   GNa = 120.0,
                   ENa = 115.0,
                   GK = 36.0,
                   EK = -12.0,
                   GL = 0.3,
                   EL = 10.598,
                   T = 18.5):

    """Returns a function for H &amp; H traveling wave simulation
    
    Formal parameters:
    a: a double, the axon radius [cm]
    Cm: a double, the membrane capacitance [μF / cm^2]
    rho: a double, intracellular resistivity [Ω cm]
    GNa: sodium conductance density [mS / cm^2]
    ENa: sodium reversal potential [mV]
    GK: potassium conductance density [mS / cm^2]
    EK: potassium reversal potential [mV]
    GL: leak conductance density [mS / cm^2]
    EL: leak reversal potential [mV]
    T: a positive double, the temperature in Celsius

    Returns:
    F: a function suitable for use with ODE, the propagation
    speed is the third formal parameter.
    """
    Q = 3**((T-6.3)/10) ## Temperature effect
    D = a*1000/2/rho/Cm ## Diffusion coefficient cm^2/ms
    def F_n(v,n):
        if np.abs(v-10.0) &lt; 1e-10:
            alpha = 0.1
        else:
            alpha = 0.01*(10.0 - v)/(np.exp((10.0-v)/10.0)-1.0)
        beta = 0.125*np.exp(-0.0125*v)
        return Q*(alpha*(1-n)-beta*n)
    def F_m(v,m):
        if np.abs(v-25.0) &lt; 1e-10:
            alpha = 1.0
        else:
            alpha =  0.1*(25.0 - v)/(np.exp((25.0 - v)/10.0)-1.0)
        beta = 4*np.exp(-.0555*v)
        return Q*(alpha*(1-m)-beta*m)
    def F_h(v,h):
        return Q*(0.07*np.exp(-0.05*v)*(1-h)-1.0/(np.exp((30.0 - v)/10.0) + 1.0)*h)
    def F_I(i,v,n,m,h,u):
        return u**2*(i-(GK*n**4*(EK-v)+GNa*m**3*h*(ENa-v)+GL*(EL-v))/Cm)/D
    def F_V(i):
        return i
    def F(t,y,u):
        v,i,n,m,h = y
        return [F_V(i),F_I(i,v,n,m,h,u),F_n(v,n),F_m(v,m),F_h(v,h)]
    return F
</pre>
</div>

<p>
We then define our initial condition from the values at 1 ms of the membrane potential, n, m and h variables at 3 cm of our previous "Cooley and Dodge check".
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock36">y0 = [v_cd[1000,80],(v_cd[1001,80]-v_cd[1000,80])/(tt[1001]-tt[1000]),n_cd[1000,80],m_cd[1000,80],h_cd[1000,80]]
</pre>
</div>

<p>
We then call the <code>lsoda</code> solver with:
</p>

<div class="org-src-container">

<pre class="src src-python">from scipy.integrate import ode
F = mk_travel_wave()
r = ode(F)
r.set_integrator('lsoda')
r.set_initial_value(y0,0.0)
r.set_f_params(1.8996800434730384) ## propagation speed is set here [cm/ms]
tt2 = np.linspace(0,10,1001)
res = np.zeros((len(tt2),5))
for i in range(1,len(tt2)): res[i] = r.integrate(tt2[i])
</pre>
</div>

<p>
<b>Getting the speed right is the result of a long trial and error procedure (think of H &amp; H who did not have a computer!).</b>
</p>

<p>
We can then superpose the two solutions we got (from the full H &amp; H model of the previous section and from the traveling wave):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock37">plt.plot(tt-1,v_cd[:,80],lw=2)
plt.plot(tt2,res[:,0])
plt.ylim(-20,100)
plt.xlabel('Time (ms)')
plt.ylabel(r'$\Delta{}V_m$ (mV)')
</pre>
</div>


<div class="figure">
<p><img src="figsL1/Cooley_and_Dodge_Traveling_wave_comp.png" alt="Cooley_and_Dodge_Traveling_wave_comp.png" />
</p>
<p><span class="figure-number">Figure 4:</span> Red: time course of the action potential obtained from a "full" H &amp; H model solution. Blue: time course of the action potential obtained from the traveling wave equation (44) with a speed of 18.99 m/s.</p>
</div>

<p>
<b>Remark that we get the same speed as the one measured from the full model giving us confidence in our codes.</b>
</p>
</div>
</div>
</div>

<div id="outline-container-orgheadline15" class="outline-2">
<h2 id="orgheadline15"><span class="section-number-2">4</span> Numerical investigation of the radius effect on the extracellular potential</h2>
<div class="outline-text-2" id="text-4">
<p>
Equation 10 shows an explicite axon's radius square but says nothing on the effect of radius change on \(\Delta{}V_m\). If we use our newly developped code to get the picture with an axon of 4 \(\mu{}m\) diameter we see that:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock38">D1(4e-4)/D1(1e-4)
</pre>
</div>

<pre class="example">
4.0
</pre>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock39">lambda1(4e-4)/lambda1(1e-4)
</pre>
</div>

<pre class="example">
2.0
</pre>

<p>
The length constant is multiplied by 2, the diffusion coefficient by 4 so we can simulate a cable twice as long with a space step twice as large while keeping the same \(r\) value. Let's do it (we increase the stimulation amplitude also):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock40">v4,n4,m4,h4 = sim1(4e-4,4,20,2*5e-3,0.025,2000,2)
</pre>
</div>

<p>
We get a graph similar to the one we got with the 1 \(\mu{}m\) radius axon with (result not shown):
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock41">xx = np.arange(v4.shape[1])*2*5e-3
for i in range(0,442,40):
    plt.plot(xx,v4[i],color='black',lw=2)
plt.xlabel('Position (cm)')
plt.ylabel(r'$\Delta{}V_m$ (mV)')
</pre>
</div>

<p>
To compare the spatial extensions, let us extract the time at which the spikes peaks at a distance of 1 cm:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock42">index_1_mu = np.argmax(v1[:,200])
index_4_mu = np.argmax(v4[:,100])
</pre>
</div>

<p>
A simple graph shows then what Goldstein and Rall (1974, <i>Biophys J</i> <b>14</b>:731-757) established with a dimensional analysis: <i>the spatial extension on an action potential is proportional to the square root of the axon's radius</i>.
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock43">plt.plot(np.arange(v1.shape[1])*5e-3,v1[index_1_mu],lw=2)
plt.plot(np.arange(v4.shape[1])*2*5e-3,v4[index_4_mu],lw=2)
plt.xlim(0.5,1.5)
plt.xlabel('Position (cm)')
plt.ylabel(r'$\Delta{}V_m$ (mV)')
</pre>
</div>


<div class="figure">
<p><img src="figsL1/voltage_spatial_profile_comparison.png" alt="voltage_spatial_profile_comparison.png" />
</p>
<p><span class="figure-number">Figure 5:</span> Spatial profile of the membrane voltage for an axon whose radius is 1 \(\mu{}m\) (red) and an axon whose radius is 4 \(\mu{}m\) (blue).</p>
</div>
</div>

<div id="outline-container-orgheadline14" class="outline-3">
<h3 id="orgheadline14"><span class="section-number-3">4.1</span> A fast way to do the job</h3>
<div class="outline-text-3" id="text-4-1">
<p>
At that stage we could simulate a lot of cases with different radii, get the corresponding voltage profiles and plug those in equation 10 to get the peak (in absolute value) extra-cellular voltages at various distances between the electrode and the axon. But we can exploit the square root relation between radius and spatial extension to get all the profiles we need from a single one. We can indeed make a cubic-spline interpolation of the first profile we obtained, say when the spike is almost all the way to the right like here:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock44">plt.plot(np.arange(v1.shape[1])*5e-3,v1[-1],lw=2)
plt.xlabel('Position (cm)')
plt.ylabel(r'$\Delta{}V_m$ (mV)')
</pre>
</div>


<div class="figure">
<p><img src="figsL1/prototypical_profile.png" alt="prototypical_profile.png" />
</p>
<p><span class="figure-number">Figure 6:</span> Prototypical profile used for interpolation</p>
</div>

<p>
We then define a function returning the membrane potential at a given position based on a cubic spline interpolation alowing the axon radius, as well as the derivative, to be specified. The location of the peak of the action potential is set at 0. We are going to perform interpolation using the <code>interpolate</code> sub-module of <code>scipy</code>:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock45">def spike(x,a=1.0,der=0,ext=1,
          xx=(np.arange(v1.shape[1])-np.argmax(v1[-1]))*50,
          yy=v1[-1]):
    from scipy import interpolate
    tck = interpolate.splrep(xx*np.sqrt(a),yy)
    return interpolate.splev(x,tck,der=der,ext=ext)
</pre>
</div>

<p>
We check that the function works:
</p>

<div class="org-src-container">

<pre class="src src-python" id="orgsrcblock46">xx = np.linspace(-7000,2000,9501)
plt.plot(xx,spike(xx,2),color='red',lw=2)
plt.plot(xx,spike(xx),color='black',lw=2)
plt.plot(xx,spike(xx,0.5),color='blue',lw=2)
plt.xlabel(r'Position ($\mu{}$m)')
plt.ylabel(r'$\Delta{}V_m$ (mV)')
</pre>
</div>


<div class="figure">
<p><img src="figsL1/spike_check.png" alt="spike_check.png" />
</p>
<p><span class="figure-number">Figure 7:</span> Membrane voltage profiles for different axon radii: 0.5 \(\mu{}m\) (blue), 1 \(\mu{}m\) (black), 2 \(\mu{}m\) (red).</p>
</div>
</div>
</div>
</div>
<div id="footnotes">
<h2 class="footnotes">Footnotes: </h2>
<div id="text-footnotes">

<div class="footdef"><sup><a id="fn.1" class="footnum" href="#fnr.1">1</a></sup> <div class="footpara"><p class="footpara">
Tuckwell follows very closely&#x2014;with due citations&#x2014;the treatment of William F. Ames (1977) <i>NUMERICAL METHODS FOR PARTIAL DIFFERENTIAL EQUATIONS</i> Academic Press.
</p></div></div>


</div>
</div></div>
<div id="postamble" class="status">
<p class="date">Date: <span class="timestamp-wrapper"><span class="timestamp">&lt;2016-01-14 jeu.&gt;</span></span></p>
<p class="author">Author: Christophe Pouzat</p>
<p class="date">Created: 2016-02-04 jeu. 17:29</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
